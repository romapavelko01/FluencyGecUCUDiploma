{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romapavelko01/FluencyGecUCUDiploma/blob/main/ukr_roberta_GECTOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj8ewYoz566l",
        "outputId": "01d2350d-012e-4add-97ec-6ecefeb33e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install requirements\n",
        "It can take ~15min (long torch install)\n",
        "\n",
        "Uncomment and run cells"
      ],
      "metadata": {
        "id": "lkeM2FKC6614"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/asivokon/unlp-2023-shared-task.git\n",
        "!git clone https://github.com/MaksTarnavskyi/gector-large.git\n",
        "\n",
        "### To save repos on Google Drive (better use UCU account)\n",
        "\n",
        "# !cp -r unlp-2023-shared-task/ /content/drive/MyDrive/UNLP/unlp-2023-shared-task\n",
        "# !cp -r gector-large/ /content/drive/MyDrive/UNLP/gector-large"
      ],
      "metadata": {
        "id": "a0v9G4d16A7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8694cfc7-a1b9-4450-8c65-e394300a2c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'unlp-2023-shared-task'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 125 (delta 76), reused 98 (delta 62), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (125/125), 4.69 MiB | 26.68 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n",
            "Cloning into 'gector-large'...\n",
            "remote: Enumerating objects: 294, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 294 (delta 30), reused 30 (delta 30), pack-reused 254\u001b[K\n",
            "Receiving objects: 100% (294/294), 11.34 MiB | 22.73 MiB/s, done.\n",
            "Resolving deltas: 100% (164/164), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is important to put the environment in the 3.8 version of Python so that there will be no errors regarding dependencies\n",
        "def change_to3_8():\n",
        "  !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 4\n",
        "  !sudo apt install python3-pip\n",
        "  !sudo apt-get install python3-distutils\n",
        "  !sudo apt-get install python3-apt\n",
        "  !sudo apt-get install --reinstall python3-distutils\n",
        "  !sudo apt-get update\n",
        "  #!pip install -r drive/MyDrive/UNLP/gector-large/requirements.txt\n",
        "  !pip3 install torch==1.7.1\n",
        "  !pip3 install allennlp==0.8.4\n",
        "  !pip3 install python-Levenshtein==0.12.1\n",
        "  !pip3 install transformers==4.2.2\n",
        "  !pip3 install sentencepiece==0.1.95\n",
        "  !pip3 install scikit-learn==0.22.2\n",
        "  !pip3 install overrides==3.1.0\n",
        "  !pip3 install numpy==1.22.4\n",
        "\n",
        "change_to3_8()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kebmbxs2kNEa",
        "outputId": "b460ed5b-f7ba-4889-aa9f-37931650681f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 4 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 2,389 kB of archives.\n",
            "After this operation, 4,933 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.8 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.8 [231 kB]\n",
            "Fetched 2,389 kB in 1s (3,395 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 122531 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-distutils is already the newest version (3.8.10-0ubuntu1~20.04).\n",
            "python3-distutils set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-apt is already the newest version (2.0.1ubuntu0.20.04.1).\n",
            "python3-apt set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 1 reinstalled, 0 to remove and 24 not upgraded.\n",
            "Need to get 141 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-distutils all 3.8.10-0ubuntu1~20.04 [141 kB]\n",
            "Fetched 141 kB in 0s (380 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 122895 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-distutils_3.8.10-0ubuntu1~20.04_all.deb ...\n",
            "Unpacking python3-distutils (3.8.10-0ubuntu1~20.04) over (3.8.10-0ubuntu1~20.04) ...\n",
            "Setting up python3-distutils (3.8.10-0ubuntu1~20.04) ...\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,240 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,175 kB]\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,049 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,699 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,344 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,378 kB]\n",
            "Fetched 13.2 MB in 2s (5,367 kB/s)\n",
            "Reading package lists... Done\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 4.5 kB/s \n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 63.7 MB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: numpy, typing-extensions, torch\n",
            "Successfully installed numpy-1.24.3 torch-1.7.1 typing-extensions-4.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting allennlp==0.8.4\n",
            "  Downloading allennlp-0.8.4-py3-none-any.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 7.4 MB/s \n",
            "\u001b[?25hCollecting flask>=1.0.2\n",
            "  Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 60.4 MB/s \n",
            "\u001b[?25hCollecting flask-cors>=3.0.7\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting conllu==0.11\n",
            "  Downloading conllu-0.11-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting sqlparse>=0.2.4\n",
            "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 221 kB/s \n",
            "\u001b[?25hCollecting pytest\n",
            "  Downloading pytest-7.3.1-py3-none-any.whl (320 kB)\n",
            "\u001b[K     |████████████████████████████████| 320 kB 83.2 MB/s \n",
            "\u001b[?25hCollecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 78.3 MB/s \n",
            "\u001b[?25hCollecting pytorch-pretrained-bert>=0.6.0\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 78.4 MB/s \n",
            "\u001b[?25hCollecting matplotlib>=2.2.3\n",
            "  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 66.0 MB/s \n",
            "\u001b[?25hCollecting awscli>=1.11.91\n",
            "  Downloading awscli-1.27.136-py3-none-any.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 61.3 MB/s \n",
            "\u001b[?25hCollecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 75.9 MB/s \n",
            "\u001b[?25hCollecting requests>=2.18\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n",
            "\u001b[K     |████████████████████████████████| 594 kB 77.8 MB/s \n",
            "\u001b[?25hCollecting numpydoc>=0.8.0\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.19\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Collecting parsimonious>=0.8.0\n",
            "  Downloading parsimonious-0.10.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[K     |████████████████████████████████| 502 kB 67.5 MB/s \n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 71.1 MB/s \n",
            "\u001b[?25hCollecting responses>=0.7\n",
            "  Downloading responses-0.23.1-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 794 kB/s \n",
            "\u001b[?25hCollecting h5py\n",
            "  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 31.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from allennlp==0.8.4) (1.24.3)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.26.136-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 64.3 MB/s \n",
            "\u001b[?25hCollecting flaky\n",
            "  Downloading flaky-3.7.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from allennlp==0.8.4) (1.7.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting gevent>=1.3.6\n",
            "  Downloading gevent-22.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 65.2 MB/s \n",
            "\u001b[?25hCollecting overrides\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Collecting spacy<2.2,>=2.0.18\n",
            "  Downloading spacy-2.1.9.tar.gz (30.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.7 MB 1.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting editdistance\n",
            "  Downloading editdistance-0.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 76.8 MB/s \n",
            "\u001b[?25hCollecting itsdangerous>=2.1.2\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Collecting importlib-metadata>=3.6.0; python_version < \"3.10\"\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting blinker>=1.6.2\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Collecting Jinja2>=3.1.2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 85.3 MB/s \n",
            "\u001b[?25hCollecting Werkzeug>=2.3.3\n",
            "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 87.1 MB/s \n",
            "\u001b[?25hCollecting click>=8.1.3\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting protobuf<4,>=3.8.0\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 63.8 MB/s \n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting Six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tomli>=1.0.0; python_version < \"3.11\"\n",
            "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc8; python_version < \"3.11\"\n",
            "  Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting regex\n",
            "  Downloading regex-2023.5.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
            "\u001b[K     |████████████████████████████████| 771 kB 74.0 MB/s \n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 67.1 MB/s \n",
            "\u001b[?25hCollecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 85.3 MB/s \n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 70.9 MB/s \n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 72.6 MB/s \n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[K     |████████████████████████████████| 300 kB 79.0 MB/s \n",
            "\u001b[?25hCollecting botocore==1.29.136\n",
            "  Downloading botocore-1.29.136-py3-none-any.whl (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 52.2 MB/s \n",
            "\u001b[?25hCollecting PyYAML<5.5,>=3.10\n",
            "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[K     |████████████████████████████████| 662 kB 66.1 MB/s \n",
            "\u001b[?25hCollecting rsa<4.8,>=3.1.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.4 MB/s \n",
            "\u001b[?25hCollecting docutils<0.17,>=0.10\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 107.8 MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.5,>=0.2.5\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[K     |████████████████████████████████| 297 kB 60.2 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 114 kB/s \n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 63.8 MB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 85.0 MB/s \n",
            "\u001b[?25hCollecting sphinx>=4.2\n",
            "  Downloading sphinx-7.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 63.2 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting types-PyYAML\n",
            "  Downloading types_PyYAML-6.0.12.9-py3-none-any.whl (14 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->allennlp==0.8.4) (4.5.0)\n",
            "Collecting wcwidth>=0.2.5\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
            "\u001b[K     |████████████████████████████████| 249 kB 86.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from gevent>=1.3.6->allennlp==0.8.4) (45.2.0)\n",
            "Collecting greenlet>=2.0.0; platform_python_implementation == \"CPython\"\n",
            "  Downloading greenlet-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
            "\u001b[K     |████████████████████████████████| 618 kB 85.7 MB/s \n",
            "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
            "  Using cached murmurhash-1.0.9-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Collecting wasabi<1.1.0,>=0.2.0\n",
            "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<1.1.0,>=0.0.6\n",
            "  Using cached srsly-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Using cached plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Processing /root/.cache/pip/wheels/f4/5b/cc/8a96be826c5d22ca28e3c30f785b22edc57ffb2d349fa780be/thinc-7.0.8-cp38-cp38-linux_x86_64.whl\n",
            "Processing /root/.cache/pip/wheels/eb/c3/92/dd0802ed4a0b14a1534ab4f38d05578d7fa73e8445f3e9d2f2/blis-0.2.4-cp38-cp38-linux_x86_64.whl\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Using cached cymem-2.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
            "Processing /root/.cache/pip/wheels/5a/d0/29/7f6993a759349eae3d0ecca7e2fbc88acdd8650b25e6c6ad8a/preshed-2.0.1-cp38-cp38-linux_x86_64.whl\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting pyasn1>=0.1.3\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 85.4 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-serializinghtml>=1.1.5\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting imagesize>=1.3\n",
            "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting alabaster<0.8,>=0.7\n",
            "  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
            "Collecting babel>=2.9\n",
            "  Downloading Babel-2.12.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 50.1 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 11.1 MB/s \n",
            "\u001b[?25hCollecting snowballstemmer>=2.0\n",
            "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.13\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 71.8 MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 12.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: jsonnet, word2number, spacy\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp38-cp38-linux_x86_64.whl size=6618946 sha256=5e5af5e575b94045ce51b38ead6ce2b1282fd4aa194c09f9089d31df2f702b21\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/9b/3d/e95f85de3c2757cc5fd0791c0d18695a429e0f5745e0149802\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5586 sha256=2df6a8555eeb8ccaf897bec0542083cbd6701c027dcdc1678c9e82c3f75ffbe2\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/f3/5a/d88198fdeb46781ddd7e7f2653061af83e7adb2a076d8886d6\n",
            "  Building wheel for spacy (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy: filename=spacy-2.1.9-cp38-cp38-linux_x86_64.whl size=49692871 sha256=54c602e7629dca3ec8f829a3d9cc0a943c6581000dfcf857e66d3e33e17a7d5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/c2/73/989e659e83b30a74acdfcb825e632b1a7dc12f39d58fe37dd6\n",
            "Successfully built jsonnet word2number spacy\n",
            "\u001b[31mERROR: botocore 1.29.136 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: sphinx 7.0.1 has requirement docutils<0.21,>=0.18.1, but you'll have docutils 0.16 which is incompatible.\u001b[0m\n",
            "Installing collected packages: itsdangerous, zipp, importlib-metadata, blinker, MarkupSafe, Jinja2, Werkzeug, click, flask, protobuf, packaging, tensorboardX, Six, flask-cors, conllu, sqlparse, pluggy, tomli, exceptiongroup, iniconfig, pytest, unidecode, idna, urllib3, certifi, charset-normalizer, requests, jmespath, python-dateutil, botocore, s3transfer, boto3, regex, tqdm, pytorch-pretrained-bert, cycler, importlib-resources, pillow, pyparsing, kiwisolver, fonttools, contourpy, matplotlib, PyYAML, pyasn1, rsa, docutils, colorama, awscli, joblib, nltk, jsonnet, sphinxcontrib-applehelp, sphinxcontrib-serializinghtml, sphinxcontrib-devhelp, imagesize, alabaster, pytz, babel, sphinxcontrib-jsmath, sphinxcontrib-qthelp, snowballstemmer, Pygments, sphinxcontrib-htmlhelp, sphinx, numpydoc, word2number, parsimonious, threadpoolctl, scipy, scikit-learn, types-PyYAML, responses, h5py, jsonpickle, flaky, wcwidth, ftfy, zope.event, zope.interface, greenlet, gevent, overrides, murmurhash, wasabi, srsly, plac, cymem, preshed, blis, thinc, spacy, editdistance, allennlp\n",
            "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.2 PyYAML-5.4.1 Pygments-2.15.1 Six-1.16.0 Werkzeug-2.3.4 alabaster-0.7.13 allennlp-0.8.4 awscli-1.27.136 babel-2.12.1 blinker-1.6.2 blis-0.2.4 boto3-1.26.136 botocore-1.29.136 certifi-2023.5.7 charset-normalizer-3.1.0 click-8.1.3 colorama-0.4.4 conllu-0.11 contourpy-1.0.7 cycler-0.11.0 cymem-2.0.7 docutils-0.16 editdistance-0.6.2 exceptiongroup-1.1.1 flaky-3.7.0 flask-2.3.2 flask-cors-3.0.10 fonttools-4.39.4 ftfy-6.1.1 gevent-22.10.2 greenlet-2.0.2 h5py-3.8.0 idna-3.4 imagesize-1.4.1 importlib-metadata-6.6.0 importlib-resources-5.12.0 iniconfig-2.0.0 itsdangerous-2.1.2 jmespath-1.0.1 joblib-1.2.0 jsonnet-0.20.0 jsonpickle-3.0.1 kiwisolver-1.4.4 matplotlib-3.7.1 murmurhash-1.0.9 nltk-3.8.1 numpydoc-1.5.0 overrides-7.3.1 packaging-23.1 parsimonious-0.10.0 pillow-9.5.0 plac-0.9.6 pluggy-1.0.0 preshed-2.0.1 protobuf-3.20.3 pyasn1-0.5.0 pyparsing-3.0.9 pytest-7.3.1 python-dateutil-2.8.2 pytorch-pretrained-bert-0.6.2 pytz-2023.3 regex-2023.5.5 requests-2.30.0 responses-0.23.1 rsa-4.7.2 s3transfer-0.6.1 scikit-learn-1.2.2 scipy-1.10.1 snowballstemmer-2.2.0 spacy-2.1.9 sphinx-7.0.1 sphinxcontrib-applehelp-1.0.4 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.1 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 sqlparse-0.4.4 srsly-1.0.6 tensorboardX-2.6 thinc-7.0.8 threadpoolctl-3.1.0 tomli-2.0.1 tqdm-4.65.0 types-PyYAML-6.0.12.9 unidecode-1.3.6 urllib3-2.0.2 wasabi-0.10.1 wcwidth-0.2.6 word2number-1.1 zipp-3.15.0 zope.event-4.6 zope.interface-6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "google",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "six",
                  "sphinxcontrib",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein==0.12.1\n",
            "  Downloading python-Levenshtein-0.12.1.tar.gz (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from python-Levenshtein==0.12.1) (45.2.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.1-cp38-cp38-linux_x86_64.whl size=166625 sha256=8b43e30c4e3ab434bf857ddbf4caa443143934087d59ba1caa578c73589c84f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/4a/07/200f37357a7f431d315287e49bdbc64c65bdadda705bfad1d9\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.2.2\n",
            "  Downloading transformers-4.2.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.2.2) (2023.5.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.2.2) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==4.2.2) (1.24.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 76.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.2.2) (4.65.0)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp38-cp38-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.2.2) (2.30.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.2.2) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.2.2) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.2.2) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.2.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.2.2) (2.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.2.2) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.2.2) (2023.5.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895255 sha256=ea4a4f63d3798579ee6b9c4b8f4abd8421a5c4e288bacb22a8dfe32e709bb6ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, filelock, tokenizers, transformers\n",
            "Successfully installed filelock-3.12.0 sacremoses-0.0.53 tokenizers-0.9.4 transformers-4.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 7.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.22.2\n",
            "  Downloading scikit_learn-0.22.2-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.2) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.2) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.22.2) (1.24.3)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-0.22.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Building wheels for collected packages: overrides\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10173 sha256=8332f8ddadb5ba876847b377115d744ae9fa7f75471558e568fc1f2ac91fd24d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/4f/72/28857f75625b263e2e3f5ab2fc4416c0a85960ac6485007eaa\n",
            "Successfully built overrides\n",
            "Installing collected packages: overrides\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 7.3.1\n",
            "    Uninstalling overrides-7.3.1:\n",
            "      Successfully uninstalled overrides-7.3.1\n",
            "Successfully installed overrides-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.22.4\n",
            "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.9 MB 7.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "Successfully installed numpy-1.22.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3l6qy3llNLp",
        "outputId": "3f928c82-04ef-41cb-8daf-c2bab3c015f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare data for training"
      ],
      "metadata": {
        "id": "Bg5CBSKt7Ggg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/UNLP\"\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def run_command(command_text: str):\n",
        "  return subprocess.run(command_text.split())\n",
        "\n",
        "def check_dir(path):\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "check_dir(path)\n",
        "check_dir(path+'/pro_data/gec-fluency/')\n",
        "check_dir(path+'/models/')\n",
        "check_dir(path+'/predictions/')\n",
        "\n",
        "command = f'python gector-large/utils/preprocess_data.py -s unlp-2023-shared-task/data/gec-fluency/train.src.tok -t unlp-2023-shared-task/data/gec-fluency/train.tgt.tok -o {path}/pro_data/gec-fluency/train'\n",
        "run_command(command)\n",
        "\n",
        "command = f'python gector-large/utils/preprocess_data.py -s unlp-2023-shared-task/data/gec-fluency/valid.src.tok -t unlp-2023-shared-task/data/gec-fluency/valid.tgt.tok -o {path}/pro_data/gec-fluency/valid'\n",
        "run_command(command)"
      ],
      "metadata": {
        "id": "9mBoRBmx6oOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6687d7a-3da8-4003-c5e1-7352ec526f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['python', 'gector-large/utils/preprocess_data.py', '-s', 'unlp-2023-shared-task/data/gec-fluency/valid.src.tok', '-t', 'unlp-2023-shared-task/data/gec-fluency/valid.tgt.tok', '-o', 'drive/MyDrive/UNLP/pro_data/gec-fluency/valid'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Experiments\n",
        "\n",
        "Base ukr roberta on fluency data"
      ],
      "metadata": {
        "id": "xnQEOtGU8T4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Default hyperparameters, --tn_prob=0.0, cold_steps=4"
      ],
      "metadata": {
        "id": "C7Wsc-72fjos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gector-large/train.py --train_set  drive/MyDrive/UNLP/pro_data/gec-fluency/train --dev_set drive/MyDrive/UNLP/pro_data/gec-fluency/valid   --model_dir drive/MyDrive/UNLP/models/111_ukr_roberta_base/tn_00_cs4 --transformer_model ukr-roberta-base --tn_prob 0.0 --cold_steps_count 4 --target_vocab_size 5000"
      ],
      "metadata": {
        "id": "jxrVg9SzfmdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on additional_confidence min_error_probability at 0.0"
      ],
      "metadata": {
        "id": "aR2L-Umkai_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction already exits, no need to run\n",
        "!python gector-large/predict.py --model_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/tn_00_cs4/best.th \\\n",
        "                  --vocab_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary --input_file unlp-2023-shared-task/data/gec-fluency/valid.src.tok \\\n",
        "                  --output_file drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/prediction_tn_00_cs_4_ac_mp_00.txt --transformer_model ukr-roberta-base --special_tokens_fix 1 --additional_confidence 0.0 --min_error_probability 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiojltbIQy2M",
        "outputId": "1d7b0c08-f52c-46ea-bdde-3ae7a826a6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "0:00:09.618657\n",
            "Produced overall corrections: 829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction in additional_confidence at 0.2 and min_error_probability at 0.5, values known to be the most optimal values for these hyperparameters for GECToR with the RoBERTa encoder"
      ],
      "metadata": {
        "id": "vYy_8c-kap1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running inference\n",
        "!python gector-large/predict.py --model_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/tn_00_cs4/best.th \\\n",
        "                  --vocab_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary --input_file unlp-2023-shared-task/data/gec-fluency/valid.src.tok \\\n",
        "                  --output_file drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/prediction_tn_00_cs_4_ac_02_mp_05.txt --transformer_model ukr-roberta-base --special_tokens_fix 1 --additional_confidence 0.2 --min_error_probability 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYaKyHz6XV8Y",
        "outputId": "e59eebd2-6181-437b-b248-ae4316ac0819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "Downloading: 100% 481/481 [00:00<00:00, 1.39MB/s]\n",
            "Downloading: 100% 1.86M/1.86M [00:00<00:00, 7.63MB/s]\n",
            "Downloading: 100% 1.40M/1.40M [00:00<00:00, 5.53MB/s]\n",
            "Downloading: 100% 150/150 [00:00<00:00, 972kB/s]\n",
            "Downloading: 100% 16.0/16.0 [00:00<00:00, 118kB/s]\n",
            "Downloading: 100% 507M/507M [00:19<00:00, 26.4MB/s]\n",
            "0:00:07.699111\n",
            "Produced overall corrections: 568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ac=0.2, mep=0.2"
      ],
      "metadata": {
        "id": "K6QiIfIixtWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gector-large/predict.py --model_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/tn_00_cs4/best.th \\\n",
        "                  --vocab_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary --input_file unlp-2023-shared-task/data/gec-fluency/valid.src.tok \\\n",
        "                  --output_file drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/prediction_tn_00_cs_4_ac_02_mp_02.txt --transformer_model ukr-roberta-base --special_tokens_fix 1 --additional_confidence 0.2 --min_error_probability 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUCgRO96xs0E",
        "outputId": "7763c132-563d-4785-f13e-e4186d5aad25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "0:00:07.984507\n",
            "Produced overall corrections: 700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tn_prob is set to 1 so that model can learn on data with no errors, thus no need to edit"
      ],
      "metadata": {
        "id": "SwndTPGOClvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gector-large/train.py --train_set  drive/MyDrive/UNLP/pro_data/gec-fluency/train --dev_set drive/MyDrive/UNLP/pro_data/gec-fluency/valid   --model_dir drive/MyDrive/UNLP/models/111_ukr_roberta_base/tn_1_cs4 --transformer_model ukr-roberta-base --tn_prob 1.0 --cold_steps_count 4 --n_epoch 25 --target_vocab_size 5000"
      ],
      "metadata": {
        "id": "cKeGMUiBEeYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on additional_confidence min_error_probability at 0.0"
      ],
      "metadata": {
        "id": "vhef50bXbHDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this prediction already exists, no run\n",
        "!python gector-large/predict.py --model_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/tn_1_cs4/best.th \\\n",
        "                  --vocab_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary --input_file unlp-2023-shared-task/data/gec-fluency/valid.src.tok \\\n",
        "                  --output_file drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/prediction_tn_1_cs_4_ac_mp_00.txt --transformer_model ukr-roberta-base --special_tokens_fix 1 --additional_confidence 0.2 --min_error_probability 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoZN15W7PFIK",
        "outputId": "7089f1aa-9670-4afe-ec32-7c4aee0f7418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "0:00:09.017029\n",
            "Produced overall corrections: 668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ac=0.2, mep=0.2"
      ],
      "metadata": {
        "id": "tnxy_z01xILO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gector-large/predict.py --model_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/tn_1_cs4/best.th \\\n",
        "                  --vocab_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary --input_file unlp-2023-shared-task/data/gec-fluency/valid.src.tok \\\n",
        "                  --output_file drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/prediction_tn_1_cs_4_ac_02_mp_02.txt --transformer_model ukr-roberta-base --special_tokens_fix 1 --additional_confidence 0.2 --min_error_probability 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW3svfaKxJ2U",
        "outputId": "af81a6f3-9a01-4a82-d3c7-d0e2bd4b78ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "0:00:07.554572\n",
            "Produced overall corrections: 537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction in additional_confidence at 0.2 and min_error_probability at 0.5, values known to be the most optimal values for these hyperparameters for GECToR with the RoBERTa encoder"
      ],
      "metadata": {
        "id": "wjGST2kgbbNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gector-large/predict.py --model_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/tn_1_cs4/best.th \\\n",
        "                  --vocab_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary --input_file unlp-2023-shared-task/data/gec-fluency/valid.src.tok \\\n",
        "                  --output_file drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/prediction_tn_1_cs_4_ac_02_mp_05.txt --transformer_model ukr-roberta-base --special_tokens_fix 1 --additional_confidence 0.2 --min_error_probability 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CfmjH3EbKPt",
        "outputId": "3a60a75d-c5cf-4dd6-beb7-f137203fce07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "0:00:07.024768\n",
            "Produced overall corrections: 402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## --cold_steps_count 2 --tn_prob 1 --special_tokens_fix 1 --target_vocab_size 5000"
      ],
      "metadata": {
        "id": "gWZXmWdCdYNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gector-large/train.py --train_set  drive/MyDrive/UNLP/pro_data/gec-fluency/train --dev_set drive/MyDrive/UNLP/pro_data/gec-fluency/valid   --model_dir drive/MyDrive/UNLP/models/111_ukr_roberta_base/ --transformer_model ukr-roberta-base --cold_steps_count 2 --tn_prob 1 --special_tokens_fix 1 --target_vocab_size 5000"
      ],
      "metadata": {
        "id": "FBiKuEKE6oUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1869de90-717d-4bd7-b480-96ed1dd1a29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.0)\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "Downloading: 100% 481/481 [00:00<00:00, 2.38MB/s]\n",
            "Downloading: 100% 1.86M/1.86M [00:00<00:00, 18.0MB/s]\n",
            "Downloading: 100% 1.40M/1.40M [00:00<00:00, 17.3MB/s]\n",
            "Downloading: 100% 150/150 [00:00<00:00, 786kB/s]\n",
            "Downloading: 100% 16.0/16.0 [00:00<00:00, 101kB/s]\n",
            "98202it [00:05, 16633.47it/s]\n",
            "WARNING:root:vocabulary serialization directory drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary is not empty\n",
            "Data is loaded\n",
            "Downloading: 100% 507M/507M [00:18<00:00, 27.9MB/s]\n",
            "Model is set\n",
            "Start training\n",
            "accuracy: 0.9594, loss: 0.2142 ||: : 3069it [03:37, 14.10it/s]\n",
            "accuracy: 0.9291, loss: 0.5140 ||: : 142it [00:09, 15.75it/s]\n",
            "Model is dumped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ac=0, mep=0"
      ],
      "metadata": {
        "id": "BQTwyHo7gV6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction exists, no run\n",
        "!python gector-large/predict.py --model_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/best.th \\\n",
        "                  --vocab_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary --input_file unlp-2023-shared-task/data/gec-fluency/valid.src.tok \\\n",
        "                  --output_file drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/prediction_ac_00_mep_00.txt --transformer_model ukr-roberta-base --special_tokens_fix 1 --additional_confidence 0.0 --min_error_probability 0.0"
      ],
      "metadata": {
        "id": "EGDPvI3h6oZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4748e5-e05c-4727-852b-4e1779e996f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.0)\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "0:00:08.328678\n",
            "Produced overall corrections: 597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ac=0.2, mep=0.5"
      ],
      "metadata": {
        "id": "yTYESZVqgSar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gector-large/predict.py --model_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/model.th \\\n",
        "                  --vocab_path drive/MyDrive/UNLP/models/111_ukr_roberta_base/vocabulary --input_file unlp-2023-shared-task/data/gec-fluency/valid.src.tok \\\n",
        "                  --output_file drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/prediction_ac_02_mep_05.txt --transformer_model ukr-roberta-base --special_tokens_fix 1 --additional_confidence 0.2 --min_error_probability 0.5"
      ],
      "metadata": {
        "id": "rsGlSMnYa-D_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101868fd-76ab-408b-e13b-d409f25ad04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "0:00:07.279719\n",
            "Produced overall corrections: 398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ac=0.2, mep=0.2"
      ],
      "metadata": {
        "id": "Mx8H84jiweII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predicition already exists"
      ],
      "metadata": {
        "id": "GBsaAWYCwgQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-2yI_SMLdPGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run inference"
      ],
      "metadata": {
        "id": "wlad60Qz8NLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_dir(path+'/predictions/111_ukr_roberta_base/')"
      ],
      "metadata": {
        "id": "eHKy9NpY9P7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('drive/MyDrive/UNLP/predictions/111_ukr_roberta_base/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_eBLevJ-bs1",
        "outputId": "a0939e0c-c2cd-4025-fb54-a760fe899149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['prediction_ac_02_mep_02.txt', 'prediction_ac_00_mep_00.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}